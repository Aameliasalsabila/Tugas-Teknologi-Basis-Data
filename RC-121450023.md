# TUGAS TBD RC
Nama : Salwa Amelia Salsabila \
NIM : 121450023 \
KELAS : RC

# Tiga cara menyimpan dan mengakses banyak gambar dengan python
pada artikel dari real python yang berjudul "tiga cara menyimpan dan mengakses banyak gambar dengan python" membahas mengenai cara menyimpan dan mengakses banyak gambar dengan python. pada artikel ini diberikan penjelasan jika ingin mengelompokkan beberapa gambar berdasarkan warna atau mendeteksi wajah satu per satu menggunakan OpenCV kita tidak perlu khawatir. Meskipun menggunakan Python Imaging Library (PIL) untuk menggambar beberapa ratus foto, kita tetap tidak perlu melakukannya. Menyimpan gambar pada disk, sebagai .pngatau .jpgfile, cocok dan sesuai. tetapi jumlah gambar yang dibutuhkan untuk suatu tugas tertentu semakin bertambah. Algoritma CNN, dapat menangani kumpulan data gambar yang sangat besar dan bahkan belajar darinya. 

#### Dalam artikel ini kita akan melakukan hal sebagai berikut :
- Menyimpan gambar pada disk sebagai .pngfile
- Menyimpan gambar dalam database yang dipetakan memori petir (LMDB)
- Menyimpan gambar dalam format data hierarki (HDF5)

#### kita juga akan mencari hal mengenai berikut ini :
- Mengapa metode penyimpanan alternatif patut dipertimbangkan
- Apa perbedaan performa saat Anda membaca dan menulis gambar tunggal
- Apa perbedaan performa saat Anda membaca dan menulis banyak gambar
- Bagaimana perbandingan ketiga metode dalam hal penggunaan disk

pada artikel ini juga di beri tahu Jika tidak ada metode penyimpanan yang sesuai, tetapi hal yang dibutuhkan hanyalah dasar yang cukup kuat dalam Python dan pemahaman dasar tentang gambar (bahwa gambar tersebut benar-benar terdiri dari array angka multi-dimensi ) dan memori relatif, seperti perbedaan antara 10MB dan 10GB.

## Setup
### A Dataset to Play With
Pada artikel menjelaskan menggunakan kumpulan data gambar Canadian Institute for Advanced Research, yang lebih dikenal sebagai CIFAR-10 , yang terdiri dari 60.000 gambar berwarna berukuran 32x32 piksel yang termasuk dalam kelas objek berbeda, seperti anjing, kucing, dan pesawat terbang. dijelaskan juga Saat kita mengunduh dan mengekstrak folder tersebut, kita akan menemukan bahwa file tersebut bukanlah file gambar yang dapat dibaca manusia. Mereka sebenarnya telah diserialkan dan disimpan dalam batch menggunakan cPickle. dalam artikel ini, selain mengekstrak kumpulan data CIFAR, perlu disebutkan bahwa picklemodul Python memiliki keuntungan utama karena dapat membuat serialisasi objek Python apa pun tanpa kode tambahan atau transformasi apa pun di pihak kita. Hal ini juga berpotensi menimbulkan kerugian serius karena menimbulkan risiko keamanan dan tidak mampu menangani data dalam jumlah yang sangat besar dengan baik.

```
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

### Setup for Storing Images on Disk
pastikan bahwa kita telah menginstall python 3.X. selanjutnya kita akan melakukan manipulasi gambar dengan `pillow` :
```
$ pip install Pillow
```
dan kita juga dapat menginstall menggunakan `anaconda` :
```
$ conda install -c conda-forge pillow
```
terdapat juga catatan dari artikel ini yaitu : PIL adalah versi asli dari Python Imaging Library, yang tidak lagi dipertahankan dan tidak kompatibel dengan Python 3.x. Jika kita sudah menginstal sebelumnya PIL, pastikan untuk menghapus instalannya sebelum menginstal Pillow, karena keduanya tidak dapat ada bersamaan.

### Getting Started With LMDB
LMDB, sering disebut sebagai “Lightning Database,” adalah singkatan dari Lightning Memory-Mapped Database karena kecepatannya dan penggunaan file yang dipetakan memori. Jadi, bukan database relasional, LMDB menyimpan nilai kunci dalam struktur pohon B+. Pohon B+ adalah grafik mirip pohon yang disimpan dalam memori, memungkinkan traversal cepat antar simpul. Komponen kunci pohon B+ disesuaikan dengan ukuran halaman sistem operasi, meningkatkan efisiensi akses data. LMDB efisien karena dipetakan dalam memori, mengembalikan penunjuk langsung ke alamat memori kunci dan nilai tanpa perlu menyalin data. Ini memanfaatkan sistem file dan implementasi yang mendasarinya untuk kinerja yang optimal. Bagi yang ingin memahami lebih dalam, artikel tentang pohon B+ dan visualisasi penyisipan simpul bisa menjadi sumber pembelajaran yang berguna. Kemudian kita menggunakan `python binding` untuk perpustakaan LMDB C, yang dapat diinstal melalui pip:
```
$ pip install lmdb
```
kita juga dapat menginstalnya melalui `anaconda` :
```
$ conda install -c conda-forge python-lmdb
```
dan periksa apakah kita dapat melakukannya `import lmdb` dari shell Python.

### Getting Started With HDF5
Hierarchical data format (HDF5) merupakan format file yang disebut HDF4 atau HDF5. HDF berasal dari National Center for Supercomputing Applications, sebagai format data ilmiah yang portabel dan ringkas. 
#### File HDF terdiri dari 2 jenis objek :
- Kumpulan data
- Grup

Kumpulan data merupakan array multidimensi, dan terdiri dari kumpulan data atau grup lain. yang mana array multidimensi dengan ukuran dan tipe apapun dapat disimpan sebagai kumpulan data, namun dimensi dan tipenya harus seragam dalam kumpulan data. Setiap dataset harus berisi array berdimensi N yang homogen. karena grup dan kumpulan data mungkin disarangkan, kita masih bisa mendapatkan heterogenitas yang mungkin diperlukan:
```
$ pip install h5py
```
kita juga dapat menginstalnya melalui `anaconda` :
```
$ conda install -c conda-forge h5py
```
dan periksa apakah kita dapat melakukannya `import h5py` dari shell Python.

## Storing a Single Image
Dalam artikel ada beberapa tugas-tugas dasar yang penting seperti : berapa lama waktu yang dibutuhkan untuk membaca dan menulis file, dan berapa banyak memori disk yang akan digunakan. Ini juga akan berfungsi sebagai pengenalan dasar tentang cara kerja metode, dengan contoh kode cara menggunakannya. Untuk keperluan eksperimen, kita dapat membandingkan kinerja antara berbagai jumlah file, dengan faktor 10 dari satu gambar hingga 100.000 gambar. Karena lima kumpulan CIFAR-10 kami berjumlah 50.000 gambar, kami dapat menggunakan setiap gambar dua kali untuk mendapatkan 100.000 gambar.\
terdapat beberapa yang perlu dilakuakn yaitu membuat folder untuk setiap metode, yang akan berisi semua file atau gambar database, dan menyimpan jalur ke direktori tersebut dalam variabel:
```
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```
`Path` tidak secara otomatis membuat folder untuk kita kecuali kita secara khusus memintanya untuk:
```
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```
selanjutnya kita bisa menjalankan eksperimen. Kita dapat menggunakan `timeitmodul`, yang disertakan dalam pustaka standar Python, untuk membantu mengatur waktu eksperimen. tujuan utama artikel ini bukan untuk mempelajari API dari berbagai paket Python tetapi sangat membantu jika kita memahami bagaimana paket tersebut dapat diimplementasikan.

#### Storing to Disk
di percobaan ini terdapat satu gambar `image`, yang saat ini ada di memori sebagai array NumPy. kita ingin menyimpannya terlebih dahulu ke disk sebagai `.pngimage`, dan menamainya menggunakan image ID yang unik `image_id`. Ini dapat dilakukan dengan menggunakan `Pillow` paket yang Anda instal sebelumnya:
```
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```
kode di atas adalah cara simpan gambar, ketika kita simpan gambar, misalnya label gambar. Ada beberapa cara buat simpen data tambahan itu. Misalnya, bisa masukin label ke nama gambar langsung. Namun, ini juga memiliki kelemahan besar karena memaksa kita menangani semua file setiap kali kita melakukan sesuatu dengan label. Menyimpan label dalam file terpisah memungkinkan kita bermain-main dengan label saja, tanpa harus memuat gambar. Di atas, kita telah menyimpan label dalam `.csvfile` terpisah untuk percobaan ini.

### Storing to LMDB
Dalam kasus ini kunci akan menjadi pengidentifikasi unik untuk setiap gambar, dan nilainya akan menjadi gambar itu sendiri. Baik kunci maupun nilai diharapkan berupa strings , jadi penggunaan umum adalah membuat serial nilai sebagai string, lalu membatalkan serialisasinya saat membacanya kembali. kita dapat mengggunakan `pickle` untuk serialisasi.
kita dapat membuat `class python` dasar untuk gambar dan meta datanya : 
```
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary 
        # for this dataset, but some datasets may include images of 
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```
karena LMDB menggunakan pemetaan memori, yang membutuhkan perkiraan jumlah memori yang akan digunakan oleh database. Ini cukup sederhana untuk kasus kami, tapi bisa rumit di kasus lain, seperti yang akan dijelaskan lebih lanjut nanti. LMDB menyebut ini sebagai map_size. Selain itu, baca dan tulis dengan LMDB dilakukan dalam transaksi, yang bisa dianggap seperti serangkaian operasi pada database tradisional. \
berikut ini kode untuk menyimpan satu gambar ke LMDB :
```
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```
### Storing With HDF5
HDF5 dapat berisi lebih dari satu kumpulan data. kita dapat membuat 2 himpunan data, stau untuk gambar, dan satu untuk metadanya : 
```
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```
`h5py.h5t.STD_U8BE` menentukan jenis data yang akan disimpan dalam kumpulan data, yang dalam hal ini adalah bilangan bulat 8-bit yang tidak ditandatangani.

### Experiments for Storing a Single Image
Kita dapat memasukkan ketiga fungsi untuk menyimpan satu gambar ke dalam `dictionary` dengan kode sebagai berikut : 
```
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```
selanjutnya kita coba menyimpan gambar pertama dari CIFAR dan label terkait, lalu menyimpannya dengan tiga cara berbeda:
```
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
dari kodingan yang telah dilakukan dapat disimpulkan yaitu :
- Semua metode ini cukup cepat.
- Dalam hal penggunaan disk, LMDB menggunakan lebih banyak.
meskipun LMDB memiliki sedikit keunggulan kinerja, kami belum meyakinkan siapa pun mengapa tidak menyimpan gambar saja di disk. Bagaimanapun, ini adalah format yang dapat dibaca manusia, dan kita dapat membuka dan melihatnya dari browser sistem file apa pun.

## Storing Many Images
### Adjusting the Code for Many Images
Kita menginginkan konsistensi dalam database file agar setiap gambar dapat dimasukkan ke dalam satu atau beberapa file, bukan membuat file database yang berbeda untuk setiap gambar. Dalam hal ini, diperlukan penyesuaian kode dengan pembuatan tiga fungsi baru, yaitu `store_many_disk()`, `store_many_lmdb()`, dan `store_many_hdf5()`:
```
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```
agar dapat menyimpan lebih dari satu file ke disk, metode file gambar diubah untuk mengulang setiap gambar dalam daftar. Untuk menggunakan LMDB, kita juga perlu melakukan looping karena kita membuat objek CIFAR_Image untuk setiap gambar dan metadata-nya.
Sebaliknya, ketika menggunakan metode HDF5, penyesuaian minimal diperlukan. Faktanya, hampir tidak ada penyesuaian sama sekali! File HDF5 tidak terbatas pada ukuran file, kecuali batasan eksternal atau ukuran kumpulan data, sehingga semua gambar dapat dimasukkan ke dalam satu kumpulan data seperti sebelumnya.

### Preparing the Dataset
pertama kita akan melakukan penggandaan ukuran kumpulan data kita sehingga kita dapat menguji hingga 100.000 gambar:
```
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```
### Experiment for Storing Many Images
lalu akan membuat dictionary yang menangani semua fungsi `store_many_` :
```
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```
dan dari kodingan tersebut akan tersimpan 111.110 gambar disimpan masing-masing tiga kali ke disk dalam 3 format berbeda. dan pada artikel ditampilkan grafik yang mana terdapat 2 grafik untuk menjawab permasalahan Berapa lama waktu yang dibutuhkan untuk semua penyimpanan itu?. Pada Diagram pertama memperlihatkan perbedaan besar dalam waktu penyimpanan antara metode normal dan metode yang disesuaikan, dengan fokus pada perbedaan antara menyimpan ke format .png dan menggunakan LMDB atau HDF5. Diagram kedua menunjukkan perubahan waktu dalam skala logaritmik, menunjukkan bahwa meskipun HDF5 memulai prosesnya dengan kecepatan lebih rendah daripada LMDB, namun dengan meningkatnya jumlah gambar, HDF5 menjadi sedikit lebih cepat. inilah alasan mengapa LMDB dan HDF5 layak untuk dipertimbangkan. Berikut kode yang menghasilkan grafik di atas:
```
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```
## Reading a Single Image
### Reading From Disk
dari ketiga metode LMDB memerlukan kerja keras paling banyak saat membaca kembali file gambar dari memori, karena langkah serialisasi. langkah pertama kita akan membaca dan metarnya dari file `.png` dan `.csv` :
```
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```
### Reading From LMDB
lalu kita akan membaca gambar dan meta yang sama dari LMDB dengan membuka lingkungan dan memulai transaksi baca :
```
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```
### Reading From HDF5
di tahap ini kita akan membuka dan membaca file HDF5 serta mengurai gambar dan meta yang sama :
```
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```
kemudian kita membuat kamus yang berisi semua fungsi baca : 
```
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

### Experiment for Reading a Single Image
dalam tahap ini akan di tampilkan kode eksperimennya : 
```
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```
dan didapatkan hasil percobaan membaca satu gambar untuk metode disk sekitar 1,61970 mdtk, LMDB sekitar 4,52063 mdtk, dan HDFS sekitar 1,98036 mdtk. yang dapat kita lihat bahwa ini sedikit lebih cepat untuk membaca `.png` dan `.csv` file langsung dari disk, tetapi ketiga metode tersebut bekerja dengan sangat cepat.
## Reading Many Images
### Adjusting the Code for Many Images
pada bagian ini kita membuat fungsi read_many_, yang digunakan untuk percobaan : 
```
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object 
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```
### Experiment for Reading Many Images
selanjutnya ditahap ini kita akan membaca banyak gambar : 
```
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```
ditampilkan 2 grafik yang mana pada diagram pertama menampilkan perbedaan besar dalam waktu baca antara metode konvensional dan metode yang disesuaikan, menekankan perbedaan antara membaca dari format .png dan menggunakan LMDB atau HDF5.
Sementara itu, diagram kedua menunjukkan perubahan waktu dalam skala logaritmik, menggambarkan perbedaan relatif saat jumlah gambar berkurang. Ini menunjukkan bahwa meskipun HDF5 memulai dengan kecepatan yang lebih rendah, namun dengan lebih banyak gambar, secara konsisten menjadi lebih cepat daripada LMDB dengan perbedaan yang kecil. Dalam praktiknya, waktu menulis seringkali kurang penting dibandingkan waktu membaca.\
kemudian kita melihat kembali perbedaan antara waktu baca 40 detik dan 4 detik dengan perbedaan antara menunggu enam jam hingga model Anda dilatih, atau empat puluh menit. didaptkan Ketika kita menyimpan gambar sebagai file `.png`, terdapat perbedaan yang signifikan antara waktu penulisan dan pembacaannya. Namun, perbedaannya tidak sebesar itu saat menggunakan LMDB atau HDF5. Secara keseluruhan, meskipun waktu baca lebih penting, ada alasan yang kuat untuk memilih LMDB atau HDF5 untuk menyimpan gambar.
## Considering Disk Usage
ruang disk merupakan masalah yang sanagt valid dan relevan. dan pada bagian ini kita akan mencari **Berapa banyak ruang disk yang digunakan berbagai metode penyimpanan?** berikut ini kodingannya :
```
# Memory used in KB
disk_mem = [24, 204, 2004, 20032, 200296]
lmdb_mem = [60, 420, 4000, 39000, 393000]
hdf5_mem = [36, 304, 2900, 29000, 293000]

X = [disk_mem, lmdb_mem, hdf5_mem]

ind = np.arange(3)
width = 0.35

plt.subplots(figsize=(8, 10))
plots = [plt.bar(ind, [row[0] for row in X], width)]
for i in range(1, len(cutoffs)):
    plots.append(
        plt.bar(
            ind, [row[i] for row in X], width, bottom=[row[i - 1] for row in X]
        )
    )

plt.ylabel("Memory in KB")
plt.title("Disk memory used by method")
plt.xticks(ind, ("PNG", "LMDB", "HDF5"))
plt.yticks(np.arange(0, 400000, 100000))

plt.legend(
    [plot[0] for plot in plots], ("10", "100", "1,000", "10,000", "100,000")
)
plt.show()
```
dan dari barplot yang dihasilkan Baik HDF5 maupun LMDB membutuhkan lebih banyak ruang disk daripada menyimpan gambar dalam format.png. Efisiensi LMDB bergantung pada caching dan ukuran halaman OS, tetapi penggunaan disk meningkat secara signifikan dengan gambar yang lebih besar. Untuk gambar berukuran 32 x 32 x 3 piksel, LMDB memberikan kinerja terbaik. Meskipun tidak diteliti secara khusus dalam eksperimen ini, dari pengalaman dengan gambar berukuran lebih besar, HDF5 cenderung sedikit lebih efisien dalam pengguan disk daripada LMDB.

## Discussion
### Parallel Access
Eksperimen sebelumnya tidak menguji perbandingan utama pembacaan dan penulisan secara bersamaan. Paralelisasi dapat mempercepat pekerjaan kita dalam pengaturan besar. Meskipun menyimpan gambar sebagai `.png` memungkinkan persaingan penuh, LMDB memungkinkan beberapa pembaca berjalan bersamaan, tetapi hanya satu penulis, tanpa pemblokiran pembaca. Kecuali kita menggunakan sistem file paralel, HDF5 menawarkan I/O paralel, tetapi akses sering berurutan. Untuk menghindari hal ini, kita dapat membagi kumpulan data kita menjadi beberapa file HDF5, sehingga setiap proses dapat menangani satu file secara terpisah.
## Conclusion
Dalam artikel ini, kita telah diperkenalkan dengan tiga cara menyimpan dan mengakses banyak gambar dengan Python.
Kita telah melihat bukti bagaimana berbagai metode penyimpanan dapat memengaruhi waktu baca dan tulis secara drastis, serta beberapa pro dan kontra dari ketiga metode yang dibahas dalam artikel ini. Meskipun menyimpan gambar sebagai `.png` mungkin cara yang paling intuitif, ada manfaat kinerja yang besar jika kita mempertimbangkan metode seperti HDF5 atau LMDB.